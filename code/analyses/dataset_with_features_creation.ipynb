{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import csv\n",
    "import collections\n",
    "from itertools import chain, cycle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.stats as ss\n",
    "import spacy\n",
    "from sklearn import preprocessing\n",
    "import re\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 35\n",
    "pd.options.display.max_colwidth = 800\n",
    "\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "\n",
    "from matplotlib import rc\n",
    "#rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('font',**{'family':'serif','serif':['Times'],'size':12})\n",
    "#rcParams['font.size'] = 12\n",
    "#rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 120kB [00:00, 16.1MB/s]                    \n",
      "2020-08-02 21:30:08 INFO: Downloading default packages for language: en (English)...\n",
      "2020-08-02 21:30:09 INFO: File exists: /Users/elisa/stanza_resources/en/default.zip.\n",
      "2020-08-02 21:30:13 INFO: Finished downloading models and saved to /Users/elisa/stanza_resources.\n",
      "2020-08-02 21:30:13 WARNING: Can not find mwt: mwt from official model list. Ignoring it.\n",
      "2020-08-02 21:30:13 WARNING: Can not find pos: pos from official model list. Ignoring it.\n",
      "2020-08-02 21:30:13 WARNING: Can not find lemma: lemma from official model list. Ignoring it.\n",
      "2020-08-02 21:30:13 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | spacy     |\n",
      "| pos       | ewt       |\n",
      "| lemma     | ewt       |\n",
      "| depparse  | ewt       |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2020-08-02 21:30:13 INFO: Use device: cpu\n",
      "2020-08-02 21:30:13 INFO: Loading: tokenize\n",
      "2020-08-02 21:30:13 INFO: Using spaCy as tokenizer\n",
      "2020-08-02 21:30:13 INFO: Loading: pos\n",
      "2020-08-02 21:30:14 INFO: Loading: lemma\n",
      "2020-08-02 21:30:14 INFO: Loading: depparse\n",
      "2020-08-02 21:30:15 INFO: Loading: ner\n",
      "2020-08-02 21:30:16 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('en')\n",
    "#parser = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')\n",
    "parser = stanza.Pipeline(lang='en', processors={'tokenize': 'spacy','mwt':'mwt','pos':'pos','lemma':'lemma'},)\n",
    "def split_tokenize_text(text, lemmatize=False):\n",
    "    sents = []\n",
    "    doc = parser(text)\n",
    "    for sent in doc.sentences:\n",
    "        if lemmatize:\n",
    "            sents.append([word.lemma for word in sent.words])\n",
    "        else:\n",
    "            sents.append([word.text for word in sent.words])\n",
    "    return sents\n",
    "\n",
    "def tokenize_text(text, lemmatize=True):\n",
    "    doc = parser(text)\n",
    "    if lemmatize:\n",
    "        return [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "    else:\n",
    "        return [word.text for sent in doc.sentences for word in sent.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "gold_file = '../../data/gold/gold_full_data/annotated_questions_responses_gold.csv'\n",
    "gold_df = pd.read_csv(gold_file, index_col=False, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string columns back to tuples\n",
    "columns = ['gold_label_set', 'gold_act_set', 'gold_acts','gold_intents','gold_intent_set','gold_coarse_labels', 'gold_fine_labels', \n",
    "           'gold_workers', 'gold_sentiments', 'gold_explanations',\n",
    "           'gold_q_intents', 'gold_q_sentiments',\n",
    "           'gold_work_times', 'gold_assignment_ids', 'gold_hit_ids', 'coarse_labels', 'fine_labels',\n",
    "           'workers', 'sentiments', 'explanations']\n",
    "for column in columns:\n",
    "    gold_df[column] = [ast.literal_eval(x) for x in gold_df[column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_row(row):\n",
    "    plural_column_names = ['gold_coarse_labels','gold_acts','gold_intents', \n",
    "                          'gold_fine_labels', 'gold_workers', 'gold_sentiments',\n",
    "                          'gold_explanations', 'gold_q_intents', 'gold_q_sentiments',\n",
    "                          'gold_work_times', 'gold_assignment_ids', 'gold_hit_ids',\n",
    "                          'coarse_labels', 'fine_labels', 'workers', 'sentiments',\n",
    "                          'explanations', 'r_text_tokenized', 'q_text_tokenized',\n",
    "                          'gold_explanation_tokenized']\n",
    "    \n",
    "    lists_dict = {'gold_coarse_label': row['gold_coarse_labels'],\n",
    "         'gold_act': row['gold_acts'],\n",
    "         'gold_intent': row['gold_intents'],\n",
    "         'gold_fine_label': row['gold_fine_labels'],\n",
    "         'gold_worker': row['gold_workers'],\n",
    "         'gold_sentiment': row['gold_sentiments'],\n",
    "         'gold_explanation': row['gold_explanations'],\n",
    "         'gold_q_intent': row['gold_q_intents'],\n",
    "         'gold_q_sentiment': row['gold_q_sentiments'],\n",
    "         'gold_work_time': row['gold_work_times'],\n",
    "         'gold_assignment_id': row['gold_assignment_ids'],\n",
    "        'gold_hit_id': row['gold_hit_ids']\n",
    "        }\n",
    "    df = pd.DataFrame(lists_dict)\n",
    "    column_names = row.index\n",
    "    for column_name in column_names:\n",
    "        if column_name not in plural_column_names:\n",
    "            if not isinstance(row[column_name], tuple):\n",
    "                df[column_name] = row[column_name]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_length(list_of_lists):\n",
    "    return len(list(chain.from_iterable(list_of_lists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df['r_text_tokenized'] = gold_df.apply(lambda x: split_tokenize_text(x['r_text'], lemmatize=False), axis=1)\n",
    "gold_df['r_text_num_sents'] = gold_df['r_text_tokenized'].str.len()\n",
    "gold_df['r_text_len'] = gold_df.apply(lambda x: get_document_length(x['r_text_tokenized']), axis=1)\n",
    "\n",
    "gold_df['q_text_tokenized'] = gold_df.apply(lambda x: split_tokenize_text(x['q_text'], lemmatize=False), axis=1)\n",
    "gold_df['q_text_num_sents'] = gold_df['q_text_tokenized'].str.len()\n",
    "gold_df['q_text_len'] = gold_df.apply(lambda x: get_document_length(x['q_text_tokenized']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add question type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 120kB [00:00, 4.70MB/s]                    \n",
      "2020-08-02 21:46:04 INFO: Downloading default packages for language: en (English)...\n",
      "2020-08-02 21:46:05 INFO: File exists: /Users/elisa/stanza_resources/en/default.zip.\n",
      "2020-08-02 21:46:09 INFO: Finished downloading models and saved to /Users/elisa/stanza_resources.\n",
      "2020-08-02 21:46:09 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | spacy     |\n",
      "| pos       | ewt       |\n",
      "| lemma     | ewt       |\n",
      "| depparse  | ewt       |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2020-08-02 21:46:09 INFO: Use device: cpu\n",
      "2020-08-02 21:46:09 INFO: Loading: tokenize\n",
      "2020-08-02 21:46:09 INFO: Using spaCy as tokenizer\n",
      "2020-08-02 21:46:09 INFO: Loading: pos\n",
      "2020-08-02 21:46:10 INFO: Loading: lemma\n",
      "2020-08-02 21:46:10 INFO: Loading: depparse\n",
      "2020-08-02 21:46:11 INFO: Loading: ner\n",
      "2020-08-02 21:46:12 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/Users/elisa/Documents/CompLing/congressional_hearing/code/analyses/')\n",
    "import question_classifier as qc\n",
    "question_type_tuples = qc.get_question_types(list((gold_df['q_text']).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt_series = pd.Series(dict(question_type_tuples),name='question_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df = pd.concat([gold_df, qt_series],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_question_and_rest(text):\n",
    "    doc = parser(text)\n",
    "    sents = []\n",
    "    for s_idx, sentence in enumerate(doc.sentences):\n",
    "        if sentence.words[-1].text == \"?\":\n",
    "            for after_sent in doc.sentences[(s_idx):]:\n",
    "                sents.append(after_sent.text.strip(' '))\n",
    "            break\n",
    "    return ' '.join(sents)\n",
    "\n",
    "def get_last_question_and_rest(text):\n",
    "    doc = parser(text)\n",
    "    sents = []\n",
    "    for s_idx, sentence in enumerate(reversed(doc.sentences)):\n",
    "        if sentence.words[-1].text == \"?\":\n",
    "            sents.append(sentence.text.strip(' '))\n",
    "            if s_idx > 0:\n",
    "                for after_sent in doc.sentences[(s_idx*-1):]:\n",
    "                    sents.append(after_sent.text.strip(' '))\n",
    "            break\n",
    "    return ' '.join(sents)\n",
    "\n",
    "gold_df['q_text_first_question_and_rest'] = gold_df.apply(lambda x: get_first_question_and_rest(x['q_text']), axis=1)\n",
    "gold_df['q_text_last_question_and_rest'] = gold_df.apply(lambda x: get_last_question_and_rest(x['q_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_last_question(text):\n",
    "    doc = parser(text)\n",
    "    for sentence in reversed(doc.sentences):\n",
    "        if sentence.words[-1].text == \"?\":\n",
    "            return sentence.text.strip(' ')\n",
    "gold_df['q_text_last_question'] = gold_df.apply(lambda x: get_last_question(x['q_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df['q_text_last_question_len'] = gold_df['q_text_last_question'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def intent_to_binary(intents):\n",
    "    binary_intents = []\n",
    "    intent_to_binary = {'direct':0, 'overans':1, 'dodge':1, 'correct':0, \n",
    "                        'lying':1, 'sincere':0}\n",
    "    \n",
    "    for intent in intents:\n",
    "        binary_intents.append(intent_to_binary[intent])\n",
    "    return binary_intents\n",
    "\n",
    "gold_df['gold_intents_binary'] = gold_df.apply(lambda x: intent_to_binary(x['gold_intents']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_to_coarse_dict = {'veryNegative': 'negative', 'negative': 'negative', 'somewhatNegative': 'negative',\n",
    "                                   'neutral': 'neutral',\n",
    "                                   'veryPositive': 'positive', 'positive': 'positive', 'somewhatPositive': 'positive'}\n",
    "\n",
    "def map_fine_to_coarse(row, column_name, fine_to_coarse_dict):\n",
    "    fine_labels = row[column_name]\n",
    "    coarse_labels = []\n",
    "    for label in fine_labels:\n",
    "        coarse_labels.append(fine_to_coarse_dict[label])\n",
    "    return tuple(coarse_labels)\n",
    "gold_df['gold_sentiments_coarse'] = gold_df.apply(map_fine_to_coarse, args=('gold_sentiments', fine_to_coarse_dict,), axis=1)\n",
    "gold_df['gold_q_sentiments_coarse'] = gold_df.apply(map_fine_to_coarse, args=('gold_q_sentiments', fine_to_coarse_dict,), axis=1)                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_num(row, column, mapping_dict):\n",
    "    nums = []\n",
    "    labels = row[column]\n",
    "    for label in labels:\n",
    "        nums.append(mapping_dict[label])\n",
    "    return ' '.join(str(num) for num in nums)\n",
    "\n",
    "def get_count(row, column_name, label_names):\n",
    "    counts = []\n",
    "    for label in label_names:\n",
    "        counts.append(row[column_name].count(label))\n",
    "    return ' '.join(map(str, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_sent_to_num_dict = {\"negative\": -1, \"neutral\": 0, \"positive\": 1}\n",
    "\n",
    "gold_df['gold_sentiments_coarse_num'] = gold_df.apply(map_to_num, args=('gold_sentiments_coarse', coarse_sent_to_num_dict,), axis=1)\n",
    "gold_df['gold_q_sentiments_coarse_num'] = gold_df.apply(map_to_num, args=('gold_q_sentiments_coarse', coarse_sent_to_num_dict,), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "coarse_sent_labels = ['negative', 'neutral', 'positive']\n",
    "mlb_coarse_sent = preprocessing.MultiLabelBinarizer(classes=coarse_sent_labels) # set ordering\n",
    "\n",
    "gold_df['gold_sentiments_coarse_binary'] = [' '.join(map(str, label_set)) for label_set in mlb_coarse_sent.fit_transform(gold_df['gold_sentiments_coarse'].values)]      \n",
    "gold_df['gold_sentiments_coarse_count'] = gold_df.apply(get_count, args=('gold_sentiments_coarse', coarse_sent_labels,), axis=1)\n",
    "\n",
    "gold_df['gold_q_sentiments_coarse_binary'] = [' '.join(map(str, label_set)) for label_set in mlb_coarse_sent.fit_transform(gold_df['gold_q_sentiments_coarse'].values)]      \n",
    "gold_df['gold_q_sentiments_coarse_count'] = gold_df.apply(get_count, args=('gold_q_sentiments_coarse', coarse_sent_labels,), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"answer\", \"answer_overans-sway\", \"shift-dodge\", \"shift-correct\", \n",
    "                \"cant-answer-lying\", \"cant-answer-sincere\"]\n",
    "mlb = preprocessing.MultiLabelBinarizer(classes=class_labels) # set ordering\n",
    "\n",
    "def digitize_index(qa_index):\n",
    "    return re.sub(r'\\D', '', qa_index)\n",
    "\n",
    "gold_df['gold_labels_binary'] = [''.join(map(str, label_set)) for label_set in mlb.fit_transform(gold_df['gold_label_set'].values)]\n",
    "gold_df['qa_index_digits'] = gold_df.apply(lambda x: digitize_index(x['qa_index']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df['hit_order'] = pd.to_numeric(gold_df['hit_order'], downcast='integer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add other columns for speaker info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_name(speaker):\n",
    "    names = speaker.split(' ')\n",
    "    return names[-1]\n",
    "gold_df['q_speaker_last_name'] = gold_df.apply(lambda x: get_last_name(x['q_speaker']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_questions(text):\n",
    "    doc = parser(text)\n",
    "    questions = []\n",
    "    for sentence in doc.sentences:\n",
    "        if sentence.words[-1].text == \"?\":\n",
    "            questions.append(sentence.text.strip(' '))\n",
    "    return ' '.join(questions)\n",
    "gold_df['q_text_all_questions'] = gold_df.apply(lambda x: get_all_questions(x['q_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_n_sents(text, n):\n",
    "    doc = parser(text)\n",
    "    sents = []\n",
    "    n_sents = n\n",
    "    if len(doc.sentences) <= n:\n",
    "        n_sents = len(doc.sentences)\n",
    "    for sent in doc.sentences[-n_sents:]:\n",
    "        sents.append(sent.text.strip(' '))\n",
    "    return ' '.join(sents)\n",
    "gold_df['q_text_last_2_sents'] = gold_df.apply(lambda x: get_last_n_sents(x['q_text'], 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df['q_text_last_3_sents'] = gold_df.apply(lambda x: get_last_n_sents(x['q_text'], 3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "qintent_labels = [\"attack\", \"neutral\", \"favor\"]\n",
    "qintent_to_num_dict = {\"attack\": -1, \"neutral\": 0, \"favor\": 1}\n",
    "        \n",
    "gold_df['gold_q_intents_num'] = gold_df.apply(map_to_num, args=('gold_q_intents', qintent_to_num_dict,), axis=1)\n",
    "\n",
    "mlb_qintent = preprocessing.MultiLabelBinarizer(classes=qintent_labels) # set ordering\n",
    "gold_df['gold_q_intents_binary'] = [' '.join(map(str, label_set)) for label_set in mlb_qintent.fit_transform(gold_df['gold_q_intents'].values)]\n",
    "      \n",
    "gold_df['gold_q_intents_count'] = gold_df.apply(get_count, args=('gold_q_intents', qintent_labels,), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtype_to_num_dict = {\"YN\":1, \"OR\":2, \"DC\":3, \"WH\":4, \"TG\":5}\n",
    "gold_df['question_type_num'] = gold_df['question_type'].map(qtype_to_num_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_to_num_dict = {\"veryNegative\": -3, \"negative\": -2, \"somewhatNegative\": -1, \n",
    "                   \"neutral\": 0,\n",
    "                   'somewhatPositive': 1, 'positive': 2, 'veryPositive': 3}\n",
    "\n",
    "gold_df['gold_sentiments_num'] = gold_df.apply(map_to_num, args=('gold_sentiments', sent_to_num_dict,), axis=1)\n",
    "gold_df['gold_q_sentiments_num'] = gold_df.apply(map_to_num, args=('gold_q_sentiments', sent_to_num_dict,), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "sent_labels = ['veryNegative', 'negative', 'somewhatNegative', 'neutral',\n",
    "               'somewhatPositive', 'positive', 'veryPositive']\n",
    "mlb_sent = preprocessing.MultiLabelBinarizer(classes=sent_labels) # set ordering\n",
    "\n",
    "gold_df['gold_sentiments_binary'] = [' '.join(map(str, label_set)) for label_set in mlb_sent.fit_transform(gold_df['gold_sentiments'].values)]      \n",
    "gold_df['gold_sentiments_count'] = gold_df.apply(get_count, args=('gold_sentiments', sent_labels,), axis=1)\n",
    "\n",
    "gold_df['gold_q_sentiments_binary'] = [' '.join(map(str, label_set)) for label_set in mlb_sent.fit_transform(gold_df['gold_q_sentiments'].values)]      \n",
    "gold_df['gold_q_sentiments_count'] = gold_df.apply(get_count, args=('gold_q_sentiments', sent_labels,), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker_role(speaker_detail):\n",
    "    return ' '.join(speaker_detail.split(':')[-1].split(',')[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df['q_speaker_role'] = gold_df.apply(lambda x: get_speaker_role(x['q_speaker_detail']),axis=1)\n",
    "gold_df['r_speaker_role'] = gold_df.apply(lambda x: get_speaker_role(x['r_speaker_detail']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians = gold_df['q_speaker_detail'].unique()\n",
    "politicians_to_parties = {}\n",
    "politicians_to_parties['politician: SCOTT PERRY, Pennsylvania']='Republican'\n",
    "politicians_to_parties['politician: BRAD SHERMAN, California']='Democratic'\n",
    "politicians_to_parties['politician: JIM JORDAN, Ohio']='Republican'\n",
    "politicians_to_parties['politician: DARRELL E. ISSA, California, Chairman']='Republican'\n",
    "politicians_to_parties['politician: JEB HENSARLING, Texas, Chairman']='Republican'\n",
    "politicians_to_parties['politician: ELIJAH E. CUMMINGS, Maryland, Chairman']='Democratic'\n",
    "politicians_to_parties['politician: FRANK PALLONE, Jr., New Jersey']='Democratic'\n",
    "politicians_to_parties['politician: JOE BARTON, Texas']='Republican'\n",
    "politicians_to_parties['politician: Debbie Wasserman Schultz, Florida']='Democratic'\n",
    "politicians_to_parties['politician: Jim Jordan, Ohio, Ranking Minority']='Republican'\n",
    "politicians_to_parties['politician: Mark E. Green, Tennessee']='Republican'\n",
    "politicians_to_parties['politician: JOHN CONYERS, Jr., Michigan']='Democratic'\n",
    "politicians_to_parties['politician: BOB GOODLATTE, Virginia, Chairman']='Republican'\n",
    "politicians_to_parties['politician: F. JAMES SENSENBRENNER, Jr.,']='Republican'\n",
    "politicians_to_parties['politician: DARRELL E. ISSA, California']='Republican'\n",
    "politicians_to_parties['politician: ZOE LOFGREN, California']='Democratic'\n",
    "politicians_to_parties['politician: LAMAR S. SMITH, Texas']='Republican'\n",
    "politicians_to_parties['politician: JERROLD NADLER, New York']='Democratic'\n",
    "politicians_to_parties['politician: ELIJAH E. CUMMINGS, Maryland,']='Democratic'\n",
    "politicians_to_parties['politician: TED S. YOHO, Florida']='Republican'\n",
    "politicians_to_parties['politician: THEODORE E. DEUTCH, Florida']='Democratic'\n",
    "politicians_to_parties['politician: ADAM KINZINGER, Illinois']='Republican'\n",
    "politicians_to_parties['politician: MAXINE WATERS, California, Ranking']='Democratic'\n",
    "politicians_to_parties['politician: BLAINE LUETKEMEYER, Missouri']='Republican'\n",
    "politicians_to_parties['politician: CAROLYN B. MALONEY, New York']='Democratic'\n",
    "politicians_to_parties['politician: FRANK D. LUCAS, Oklahoma']='Republican'\n",
    "politicians_to_parties['politician: DAVID SCOTT, Georgia']='Democratic'\n",
    "politicians_to_parties['politician: BOB GIBBS, Ohio']='Republican'\n",
    "politicians_to_parties['politician: JIM COSTA, California']='Democratic'\n",
    "politicians_to_parties['politician: STEVE CHABOT, Ohio']='Republican'\n",
    "politicians_to_parties['politician: STEVE KING, Iowa']='Republican'\n",
    "politicians_to_parties['politician: JOHN F. TIERNEY, Massachusetts']='Democratic'\n",
    "politicians_to_parties['politician: MICHAEL R. TURNER, Ohio']='Republican'\n",
    "politicians_to_parties['politician: JOHN L. MICA, Florida']='Republican'\n",
    "politicians_to_parties['politician: ELEANOR HOLMES NORTON, District of']='Democratic'\n",
    "politicians_to_parties['politician: ANDY BARR, Kentucky']='Republican'\n",
    "politicians_to_parties['politician: JOHN SHIMKUS, Illinois']='Republican'\n",
    "politicians_to_parties['politician: RON DeSANTIS, Florida']='Republican'\n",
    "politicians_to_parties['politician: PAUL TONKO, New York']='Democratic'\n",
    "politicians_to_parties['politician: RANDY NEUGEBAUER, Texas']='Republican'\n",
    "politicians_to_parties['politician: GREG WALDEN, Oregon']='Republican'\n",
    "politicians_to_parties['politician: SCOTT H. PETERS, California']='Democratic'\n",
    "politicians_to_parties['politician: RAUL RUIZ, California']='Democratic'\n",
    "politicians_to_parties['politician: DAVID B. McKINLEY, West Virginia']='Republican'\n",
    "politicians_to_parties['politician: Chip Roy, Texas']='Republican'\n",
    "politicians_to_parties['politician: Kelly Armstrong, North Dakota']='Republican'\n",
    "politicians_to_parties['politician: Gerald E. Connolly, Virginia']='Democratic'\n",
    "politicians_to_parties['politician: Jamie Raskin, Maryland']='Democratic'\n",
    "politicians_to_parties['politician: Ranking Minority Member']='Republican'\n",
    "politicians_to_parties['politician: K. MICHAEL CONAWAY, Texas, Chairman']='Republican'\n",
    "politicians_to_parties['politician: COLLIN C. PETERSON, Minnesota,']='Democratic'\n",
    "politicians_to_parties['politician: MARCIA L. FUDGE, Ohio']='Democratic'\n",
    "politicians_to_parties['politician: AUSTIN SCOTT, Georgia']='Republican'\n",
    "politicians_to_parties['politician: BILL HUIZENGA, Michigan']='Republican'\n",
    "politicians_to_parties['politician: NYDIA M. VELAZQUEZ, New York']='Democratic'\n",
    "politicians_to_parties['politician: WILLIAM KEATING, Massachusetts']='Democratic'\n",
    "politicians_to_parties['politician: PATRICK T. McHENRY, North Carolina,']='Republican'\n",
    "politicians_to_parties['politician: SCOTT GARRETT, New Jersey']='Republican'\n",
    "politicians_to_parties['politician: MATT CARTWRIGHT, Pennsylvania']='Democratic'\n",
    "politicians_to_parties['politician: MICK MULVANEY, South Carolina']='Republican'\n",
    "politicians_to_parties['politician: GWEN MOORE, Wisconsin']='Democratic'\n",
    "politicians_to_parties['politician: JERROLD NADLER, New York, Chairman']='Democratic'\n",
    "politicians_to_parties['politician: ANNA G. ESHOO, California']='Democratic'\n",
    "politicians_to_parties['politician: MICHAEL C. BURGESS, Texas']='Republican'\n",
    "politicians_to_parties['politician: ELIOT L. ENGEL, New York']='Democratic'\n",
    "politicians_to_parties['politician: GENE GREEN, Texas']='Democratic'\n",
    "politicians_to_parties['politician: ELIOT L. ENGEL, New York, Chairman']='Democratic'\n",
    "politicians_to_parties['politician: MICHAEL T. McCAUL, Texas, Ranking']='Republican'\n",
    "politicians_to_parties['politician: ALBIO SIRES, New Jersey']='Democratic'\n",
    "politicians_to_parties['politician: STEVAN PEARCE, New Mexico']='Republican'\n",
    "politicians_to_parties['politician: TAMMY DUCKWORTH, Illinois']='Democratic'\n",
    "politicians_to_parties['politician: GREGORY W. MEEKS, New York']='Democratic'\n",
    "politicians_to_parties['politician: SHEILA JACKSON LEE, Texas']='Democratic'\n",
    "politicians_to_parties['politician: DOUG COLLINS, Georgia, Ranking']='Republican'\n",
    "politicians_to_parties['politician: BOBBY L. RUSH, Illinois']='Democratic'\n",
    "politicians_to_parties['politician: FRED UPTON, Michigan']='Republican'\n",
    "politicians_to_parties['politician: JAMES P. McGOVERN, Massachusetts']='Democratic'\n",
    "politicians_to_parties['politician: DWIGHT EVANS, Pennsylvania']='Democratic'\n",
    "politicians_to_parties['politician: LISA BLUNT ROCHESTER, Delaware']='Democratic'\n",
    "politicians_to_parties['politician: CHERI BUSTOS, Illinois']='Democratic'\n",
    "politicians_to_parties['politician: TRENT KELLY, Mississippi']='Republican'\n",
    "politicians_to_parties['politician: SCOTT DesJARLAIS, Tennessee']='Republican'\n",
    "politicians_to_parties[\"politician: ERIC A. ``RICK'' CRAWFORD, Arkansas\"]='Republican'\n",
    "politicians_to_parties['politician: DOUG LaMALFA, California']='Republican'\n",
    "politicians_to_parties['politician: RALPH LEE ABRAHAM, Louisiana']='Republican'\n",
    "politicians_to_parties['politician: JIMMY PANETTA, California']='Democratic'\n",
    "politicians_to_parties['politician: DARREN SOTO, Florida']='Democratic'\n",
    "politicians_to_parties['politician: AL LAWSON, Jr., Florida']='Democratic'\n",
    "politicians_to_parties['politician: JAMES COMER, Kentucky']='Republican'\n",
    "politicians_to_parties['politician: GERALD E. CONNOLLY, Virginia']='Democratic'\n",
    "politicians_to_parties['politician: J. RANDY FORBES, Virginia']='Republican'\n",
    "politicians_to_parties['politician: STEVE COHEN, Tennessee']='Democratic'\n",
    "politicians_to_parties[\"politician: HENRY C. ``HANK'' JOHNSON, Jr.,\"]='Democratic'\n",
    "politicians_to_parties['politician: JASON CHAFFETZ, Utah']='Republican'\n",
    "politicians_to_parties['politician: WM. LACY CLAY, Missouri']='Democratic'\n",
    "politicians_to_parties['politician: ROBERT PITTENGER, North Carolina']='Republican'\n",
    "politicians_to_parties['politician: MICHAEL E. CAPUANO, Massachusetts']='Democratic'\n",
    "politicians_to_parties['politician: TOM EMMER, Minnesota']='Republican'\n",
    "politicians_to_parties['politician: EDWARD R. ROYCE, California']='Republican'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df['q_speaker_party'] = gold_df['q_speaker_detail'].map(politicians_to_parties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "from collections import Counter\n",
    "\n",
    "def get_entropy(labels):\n",
    "    counts = list(Counter(labels).values())\n",
    "    label_entropy = scipy.stats.entropy(counts, base=2)\n",
    "    return label_entropy\n",
    "\n",
    "gold_df['entropy'] = gold_df.apply(lambda x: get_entropy(x['gold_coarse_labels']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the entropy\n",
    "gold_df['entropy_norm'] = (gold_df['entropy']-gold_df['entropy'].min())/(gold_df['entropy'].max()-gold_df['entropy'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map to 4 buckets\n",
    "entropy_norm_to_buckets={0:0, \n",
    "                         0.5445684476282008:0.5, 0.579380164285695: 0.5,\n",
    "                         0.6126016192893443: 0.6, 0.6216097450797567: 0.6, 0.6309297535714575: 0.6,\n",
    "                         0.9821410328348753: 1, 1: 1}\n",
    "gold_df['entropy_norm_buckets'] = gold_df['entropy_norm'].map(entropy_norm_to_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.5, 1. , 0. ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df['entropy_norm_buckets'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_categories = sorted(gold_df['entropy'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy_binarized(entropy):\n",
    "    category = entropy_categories.index(entropy)\n",
    "    category_binarized = [0]*len(entropy_categories)\n",
    "    category_binarized[category] = 1\n",
    "    return ''.join(map(str, category_binarized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gold_df['entropy_binarized'] = gold_df.apply(lambda x: get_entropy_binarized(x['entropy']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy_ordinal(entropy):\n",
    "    ordinal = entropy_categories.index(entropy)\n",
    "    return ordinal\n",
    "gold_df['entropy_ordinal'] = gold_df.apply(lambda x: get_entropy_ordinal(x['entropy']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_norm_categories = sorted(gold_df['entropy_norm_buckets'].unique())\n",
    "\n",
    "def get_entropy_ordinal_buckets(entropy):\n",
    "    ordinal =entropy_norm_categories.index(entropy)\n",
    "    return ordinal\n",
    "gold_df['entropy_ordinal_buckets'] = gold_df.apply(lambda x: get_entropy_ordinal_buckets(x['entropy_norm_buckets']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expanded_dfs = gold_df.apply(expand_row, axis=1)\n",
    "expanded_dfs = expanded_dfs.tolist()\n",
    "expanded_df = pd.concat(expanded_dfs, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df['gold_explanation_tokenized'] = expanded_df.apply(lambda x: split_tokenize_text(x['gold_explanation'], lemmatize=False), axis=1)\n",
    "expanded_df['gold_explanation_num_sents'] = expanded_df['gold_explanation_tokenized'].str.len()\n",
    "expanded_df['gold_explanation_len'] = expanded_df.apply(lambda x: get_document_length(x['gold_explanation_tokenized']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_to_coarse_dict = {'veryNegative': 'negative', 'negative': 'negative', 'somewhatNegative': 'negative',\n",
    "                                   'neutral': 'neutral',\n",
    "                                   'veryPositive': 'positive', 'positive': 'positive', 'somewhatPositive': 'positive'}\n",
    "expanded_df['gold_sentiment_coarse'] = expanded_df['gold_sentiment'].map(fine_to_coarse_dict)\n",
    "expanded_df['gold_q_sentiment_coarse'] = expanded_df['gold_q_sentiment'].map(fine_to_coarse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_to_num_dict = {'veryNegative': -3, 'negative': -2, 'somewhatNegative': -1,\n",
    "                                   'neutral': 0,\n",
    "                                   'veryPositive': 3, 'positive': 2, 'somewhatPositive': 1}\n",
    "expanded_df['gold_sentiment_num'] = expanded_df['gold_sentiment'].map(sent_to_num_dict)\n",
    "expanded_df['gold_q_sentiment_num'] = expanded_df['gold_q_sentiment'].map(sent_to_num_dict)\n",
    "\n",
    "sent_coarse_to_num_dict = {'negative': -1, 'neutral': 0, 'positive': 1}\n",
    "expanded_df['gold_sentiment_coarse_num'] = expanded_df['gold_sentiment_coarse'].map(sent_coarse_to_num_dict)\n",
    "expanded_df['gold_q_sentiment_coarse_num'] = expanded_df['gold_q_sentiment_coarse'].map(sent_coarse_to_num_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add politeness features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source:\n",
    "# https://github.com/facebookresearch/intentions-perceptions/blob/master/survey_results_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import User, Utterance, Corpus, TextParser, PolitenessStrategies, FightingWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-788b36cbf0cd>:1: FutureWarning: The User class is deprecated and will be removed in a future release. Use the Speaker class instead.\n"
     ]
    }
   ],
   "source": [
    "placeholder_user = User(name=\"User\") # ConvoKit asks for user info but for this pure linguistic analysis we don't need that, so we'll just put in a dummy.\n",
    "# We use ConvoKit (convokit.cornell.edu) to extract some of the features (namely those related to politeness). So, we must first reformat the\n",
    "# text data for use with ConvoKit.\n",
    "utts = []\n",
    "# since we do not have unique IDs for comments in the data, we'll set up our own custom identification scheme: {A/B}{number}{r?} where the first component\n",
    "# identifies which survey this comment was used in, the second is just a numerical index corresponding to rows in the source data table, and the optional\n",
    "# third component distinguishes replies from initial comments (\"r\" for replies, blank for initial)\n",
    "for row in expanded_df.itertuples():\n",
    "    utts.append(Utterance(\n",
    "        text=row.q_text,\n",
    "        id='Q' + str(row.Index),\n",
    "        root='Q' + str(row.Index),\n",
    "        reply_to=None,\n",
    "        user=placeholder_user,\n",
    "        timestamp=0\n",
    "    ))\n",
    "    utts.append(Utterance(\n",
    "        text=row.q_text_last_question,\n",
    "        id='L' + str(row.Index),\n",
    "        root='L' + str(row.Index),\n",
    "        reply_to=None,\n",
    "        user=placeholder_user,\n",
    "        timestamp=0\n",
    "    ))\n",
    "    utts.append(Utterance(\n",
    "        text=row.r_text,\n",
    "        id='R' + str(row.Index),\n",
    "        root='R' + str(row.Index),\n",
    "        reply_to='Q' + str(row.Index),\n",
    "        user=placeholder_user,\n",
    "        timestamp=0\n",
    "    ))\n",
    "    utts.append(Utterance(\n",
    "        text=row.gold_explanation,\n",
    "        id='E' + str(row.Index),\n",
    "        root='E' + str(row.Index),\n",
    "        reply_to='R' + str(row.Index),\n",
    "        user=placeholder_user,\n",
    "        timestamp=0\n",
    "    ))\n",
    "corpus = Corpus(utterances=utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract politeness strategies using ConvoKit\n",
    "corpus = TextParser().transform(corpus)\n",
    "ps = PolitenessStrategies()\n",
    "corpus_polite = ps.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Other features will be extracted manually based on dependency parses and NER, both conducted using SpaCy.\n",
    "spacy_nlp = spacy.load('en')\n",
    "utt_ids = corpus.get_utterance_ids()\n",
    "utts = [corpus.get_utterance(i).text for i in utt_ids]\n",
    "parses = dict(zip(utt_ids, spacy_nlp.pipe(utts, n_threads=-1)))\n",
    "for utterance in corpus.iter_utterances():\n",
    "    utterance.meta['spacy'] = parses[utterance.id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature vector generation\n",
    "\n",
    "# manually-constructed lexicon of question words/phrases, derived from features discovered in Liu and Jansen (2015)\n",
    "questions_lexicon = [\n",
    "    'who',\n",
    "    'what',\n",
    "    'should',\n",
    "    'good',\n",
    "    'who is going',\n",
    "    'where',\n",
    "    'what time',\n",
    "    'want'\n",
    "]\n",
    "\n",
    "def linguistic_feature_extractor(utt):\n",
    "    # list of features that *don't* come from the politeness strategies\n",
    "    feats = {\n",
    "        'has_adjective': 0,\n",
    "        'has_cardinal_num': 0,\n",
    "        'has_modal': 0,\n",
    "        'has_adverb': 0,\n",
    "        'has_named_entity': 0,\n",
    "        'question_lexicon': 0\n",
    "    }\n",
    "    # we don't use all politeness strategies, only those directly related to prior work on subjectivity detection\n",
    "    kept_strats = set([\n",
    "        'feature_politeness_==Hedges==',\n",
    "        'feature_politeness_==Factuality==',\n",
    "        'feature_politeness_==Please==',\n",
    "        'feature_politeness_==1st_person==',\n",
    "        'feature_politeness_==2nd_person==',\n",
    "        'feature_politeness_==HASPOSITIVE==',\n",
    "        'feature_politeness_==HASNEGATIVE==',\n",
    "        'feature_politeness_==INDICATIVE==' # Elisa added!\n",
    "    ])\n",
    "    # non-politeness features are extracted based on SpaCy language features\n",
    "    for token in utt.meta['spacy']:\n",
    "        if token.pos_ == 'ADJ':\n",
    "            feats['has_adjective'] = 1\n",
    "        if token.tag_ == 'CD':\n",
    "            feats['has_cardinal_num'] = 1\n",
    "        if token.tag_ == 'MD' and token.text.lower() != 'will':\n",
    "            feats['has_modal'] = 1\n",
    "        if token.pos_ == 'ADV' and token.text.lower()!= 'not':\n",
    "            feats['has_adverb'] = 1\n",
    "        if token.ent_type_ in set(['NORP', 'ORG', 'GPE', 'LOC', 'PRODUCT', 'EVENT', 'LAW', 'DATE', 'TIME', 'PERCENT', 'MONEY', 'QUANTITY']):\n",
    "            feats['has_named_entity'] = 1\n",
    "    if any(li in utt.text.lower() for li in questions_lexicon):\n",
    "        feats['question_lexicon'] = 1\n",
    "    # update the feature vector (currently containing features from `feats`) with the relevant politeness strategies\n",
    "    feats.update({k: v for k, v in utt.meta['politeness_strategies'].items()})# if k in kept_strats})\n",
    "    # additionally include demographic variables to act as controls in the regression analysis\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-52-9e15148d5a18>:7: FutureWarning: utterance.root is deprecated and will be removed in a future release. Use utterance.conversation_id instead.\n",
      "<ipython-input-52-9e15148d5a18>:8: FutureWarning: utterance.root is deprecated and will be removed in a future release. Use utterance.conversation_id instead.\n",
      "<ipython-input-52-9e15148d5a18>:10: FutureWarning: utterance.root is deprecated and will be removed in a future release. Use utterance.conversation_id instead.\n",
      "<ipython-input-52-9e15148d5a18>:12: FutureWarning: utterance.root is deprecated and will be removed in a future release. Use utterance.conversation_id instead.\n",
      "<ipython-input-52-9e15148d5a18>:14: FutureWarning: utterance.root is deprecated and will be removed in a future release. Use utterance.conversation_id instead.\n"
     ]
    }
   ],
   "source": [
    "question_ling_feats = {}\n",
    "question_last_ling_feats = {}\n",
    "response_ling_feats = {}\n",
    "explanation_ling_feats = collections.defaultdict(list)\n",
    "for utt in corpus.iter_utterances():\n",
    "    feats = linguistic_feature_extractor(utt)\n",
    "    true_id = utt.root[1:]\n",
    "    if utt.root.startswith('Q'):\n",
    "        question_ling_feats[true_id] = feats\n",
    "    elif utt.root.startswith('L'):\n",
    "        question_last_ling_feats[true_id] = feats\n",
    "    elif utt.root.startswith('R'):\n",
    "        response_ling_feats[true_id] = feats\n",
    "    elif utt.root.startswith('E'):\n",
    "        explanation_ling_feats[true_id] = feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ling_features(row):\n",
    "    index = str(row.name)\n",
    "    q_dict = update_dict_with_prefix(question_ling_feats[index], 'q_')\n",
    "    ql_dict = update_dict_with_prefix(question_last_ling_feats[index], 'l_')\n",
    "    r_dict = update_dict_with_prefix(response_ling_feats[index], 'r_')\n",
    "    e_dict = update_dict_with_prefix(explanation_ling_feats[index], 'e_')\n",
    "    merged_dict = {**q_dict, **ql_dict, **r_dict, **e_dict}\n",
    "    return pd.Series(merged_dict)\n",
    "\n",
    "def update_dict_with_prefix(old_dict, prefix):\n",
    "    updated_keys = {key: prefix+key for key in old_dict.keys()}\n",
    "    updated_dict = dict((updated_keys[key], value) for (key, value) in old_dict.items())\n",
    "    return updated_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_df = expanded_df.apply(lambda x: add_ling_features(x), axis=1)\n",
    "ling_columns = ling_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_ling_df = pd.concat([expanded_df, ling_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_ling_df = pd.merge(expanded_ling_df, gold_df[['gold_coarse_labels','qa_index']],on=['qa_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_act = {'answer':'answer', 'answer_overans-sway':'answer','shift-dodge':'shift', 'shift-correct':'shift', 'cant-answer-lying':'cant-answer',\n",
    "       'cant-answer-sincere':'cant-answer'}\n",
    "expanded_ling_df['gold_act'] = expanded_ling_df['gold_coarse_label'].map(label_to_act)\n",
    "label_to_intent = {'answer':'direct', 'answer_overans-sway':'overans','shift-dodge':'dodge', 'shift-correct':'correct', 'cant-answer-lying':'lying',\n",
    "       'cant-answer-sincere':'sincere'}\n",
    "expanded_ling_df['gold_intent'] = expanded_ling_df['gold_coarse_label'].map(label_to_intent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_ling_df.to_csv('../../data/gold/gold_full_data/expanded_with_features_annotated_questions_responses_gold.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(row, feature_name):\n",
    "    qa_index = row['qa_index']\n",
    "    if 'tokenized' in feature_name:\n",
    "        feature_value = expanded_ling_df[expanded_ling_df['qa_index']==qa_index][feature_name].values[0]\n",
    "    else:\n",
    "        feature_value = expanded_ling_df[expanded_ling_df['qa_index']==qa_index][feature_name].unique()\n",
    "        if len(feature_value) > 1:\n",
    "            feature_value = tuple(feature_value)\n",
    "        else:\n",
    "            feature_value = feature_value[0]\n",
    "    return feature_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_columns = set(expanded_ling_df.columns)\n",
    "gold_columns = set(gold_df.columns)\n",
    "new_columns = ling_columns.difference(gold_columns)\n",
    "new_columns = [col for col in new_columns if not col.startswith('gold_') or 'tokenized' in col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in new_columns:\n",
    "    gold_df[column] = gold_df.apply(add_feature, args=(column,),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some stats on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q total sents: 4096\n",
      "Q total tokens: 82582\n",
      "R total sents: 2634\n",
      "R total tokens: 48831\n"
     ]
    }
   ],
   "source": [
    "print('Q total sents:', gold_df['q_text_num_sents'].sum())\n",
    "print('Q total tokens:',gold_df['q_text_len'].sum())\n",
    "print('R total sents:',gold_df['r_text_num_sents'].sum())\n",
    "print('R total tokens:',gold_df['r_text_len'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.15"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers = expanded_ling_df.groupby(['hearing_id'])['q_speaker'].unique().values\n",
    "num_speakers = [len(speaker) for speaker in speakers]\n",
    "np.mean(num_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 18, 19, 17, 13, 13, 28, 19, 9, 24, 16, 20, 23, 29, 15, 18, 19, 11, 18, 17]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers = expanded_ling_df.groupby(['hearing_id'])['gold_worker'].unique()\n",
    "num_workers = [len(worker) for worker in workers]\n",
    "num_workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create label powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=gold_df.sort_values(by=['qa_index'])['gold_label_set'].value_counts()\n",
    "label_sets = counts.iloc[np.lexsort((counts.index, -counts.values))].index.values\n",
    "label_nums = list(map(str, list(range(len(label_sets)))))\n",
    "label_set_dict=dict(zip(label_sets,label_nums))\n",
    "\n",
    "set_labels = label_nums\n",
    "enc_set = preprocessing.OneHotEncoder(sparse=False,categories=[set_labels])\n",
    "\n",
    "index_to_powerset = {}\n",
    "for row in gold_df.sort_values(by=['qa_index']).itertuples():\n",
    "    label = label_set_dict[row.gold_label_set]\n",
    "    index_to_powerset[row.Index]=label\n",
    "powerset_df = pd.DataFrame.from_dict(index_to_powerset,orient='index',columns=['gold_label_powerset'])\n",
    "gold_df = gold_df.merge(powerset_df, left_index=True, right_index=True)\n",
    "gold_df['gold_label_powerset'] = gold_df['gold_label_powerset'].astype(str)\n",
    "gold_df['gold_label_powerset_binary'] = [''.join(map(str, map(int,label_set))) for label_set in enc_set.fit_transform(gold_df['gold_label_powerset'].values.reshape(-1, 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/elisa/Documents/CompLing/congressional_hearing/data/gold/gold_full_data/labels_to_powersets.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, label_set_dict.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(label_set_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df.sort_values(by=['qa_index']).to_csv('/Users/elisa/Documents/CompLing/congressional_hearing/data/gold/gold_full_data/with_features_annotated_questions_responses_gold.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
